{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc2b8bc-297e-4757-aed0-a341339e2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e06c3-0900-4660-b55d-51442eda4362",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c59dcf-5c17-4f5b-b24d-040181017615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54454e0-926d-41ea-b5b1-cd30bc81432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"../../../assets/aclImdb/\"\n",
    "labels = { \"pos\" : 1, \"neg\" : 0 }\n",
    "pbar = pyprind.ProgBar( 50000, stream=sys.stdout )\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for s in ( \"test\", \"train\" ):\n",
    "    for l in ( \"pos\", \"neg\" ):\n",
    "        pth = os.path.join(basepath,s,l)\n",
    "        for file in sorted(os.listdir(pth)):\n",
    "            with open(os.path.join(pth,file), 'r', encoding=\"utf-8\" ) as infile:\n",
    "                txt = infile.read()\n",
    "                tmp = pd.DataFrame( [ {txt, labels[l]} ] )\n",
    "                df  = pd.concat( [ df, tmp ], ignore_index = True )\n",
    "                pbar.update()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7d8b9-b7ce-4253-81fb-97545e7526fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df.columns = [\"label\", \"sentiment\"]\n",
    "np.random.seed(0)\n",
    "df = df.reindex( np.random.permutation( df.index ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966e4e6-3f2e-49bd-a10a-d6ec7fe9f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"movie_data.csv\", index = False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f6cd70-6a2f-4ccb-8131-1a3ac53848d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffcfa0c1-a0ec-4584-bd95-cd7c3d511e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join( basepath, \"test\", \"pos\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f89fe-cc49-4ac6-ac9f-3038d856e684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a2723d2-41f7-4da0-87bc-f45eac989cbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68afa169-2ed0-488a-982e-af7f57b9e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766b598d-ebf0-4d2c-9dfb-c2d89e722ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a416e0f2-7039-4a3e-85d7-c1d0cdc3cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.array( ['Hello <repeated> this is a text',\n",
    "                      'Another different <repeated> <repeated> <repeated> text',\n",
    "                      'what a <repeated> corpus <repeated> you got !'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "225c85f7-6443-4c7e-81f6-8a8a3fd20291",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = count.fit_transform( sentences )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc2cfe24-7c46-4f99-9329-4d85a4ed2b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 4,\n",
       " 'repeated': 6,\n",
       " 'this': 8,\n",
       " 'is': 5,\n",
       " 'text': 7,\n",
       " 'another': 0,\n",
       " 'different': 2,\n",
       " 'what': 9,\n",
       " 'corpus': 1,\n",
       " 'you': 10,\n",
       " 'got': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d031e-c3d9-4ee3-be13-0020ca278cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Each row represents a document, and the values in these vectors stands for \n",
    "    raw term frequencies.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c35c5a-c832-4e48-96be-26d6c08d093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 3, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 2, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa07a0-1dc1-4fbb-949b-c013cc61fe4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Term frequency-inverse document frequency ( tf-idf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e61de1-0824-4c53-aa0b-6c6461d048eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    * When we try to classify documents from both classes we encounter words that\n",
    "    don't belong to any of these classes. We tend to exclude these words from\n",
    "    our data.\n",
    "\n",
    "    * the tf-idf can be identified as the product of `term frequncy` and `inverse \n",
    "    document frequency`  \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fe937-8cf5-455f-81a8-73d6ccdd6753",
   "metadata": {},
   "source": [
    "$$\\Large{idf( t, d ) = \\log{\\frac{n_d}{1+df(d,t)}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c03d2-8965-4f45-9a36-8028e76cd449",
   "metadata": {},
   "source": [
    "* $\\large{n_d}: \\small{\\text{Total Number Of Docs}}$\n",
    "* ${df(d,t)}: \\small{\\text{The number of total documents, d, that contains the term, t.}}$\n",
    "* The `1` is used to elimnate the possibililty of zero denominator.\n",
    "* The `log` is used to ensure that low document frequency does not gain too much weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a60d6df-283d-4a65-81c7-f1fa851cc37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer( use_idf = True, norm = 'l2', smooth_idf=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd174d20-5991-41dd-9a0a-c9f9c541fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.5  0.5  0.3  0.38 0.5  0.   0.  ]\n",
      " [0.42 0.   0.42 0.   0.   0.   0.74 0.32 0.   0.   0.  ]\n",
      " [0.   0.43 0.   0.43 0.   0.   0.51 0.   0.   0.43 0.43]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions( precision=2 )\n",
    "print( tfidf.fit_transform( count.fit_transform( sentences ) ).toarray() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d5b8c-4114-4fab-8ffd-ed6d13c9783b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using Regex to Clean Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "818503a7-8c82-4134-a74b-2c66a58621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5bf4fdc-c507-498e-93ef-0c9b22bef1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    text = re.sub( r\"<[^>]*>\", \" \", text )\n",
    "    emoticosn = re.findall( r\"(?::|;|=)(?:-)?(?:\\(|\\)|P|D)\", text )\n",
    "    text = re.sub( r\"[\\W]+\", \" \", text.lower() )\n",
    "    return (text + ' '.join(emoticosn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4890915-566a-41e9-be33-92f5ac52ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticosn = re.findall( r\"(?::|;|=)(?:-)?(?:\\(|\\)|P|D)\", \"asdijasd :( =) :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e80c8e2a-2f84-44b8-af3a-6c309daa89cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' :)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(\":)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0170ea7b-589e-44ba-88ab-c8f8a73a9d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"at a Saturday matinee in my home town. I went with an older friend (he was about 12) and my mom let me go because she thought the film would be OK (it's rated G). I was assaulted by loud music, STRANGE images, no plot and a stubborn refusal to make ANY sense. We left halfway through because we were bored, frustrated and our ears hurt. <br /><br />I saw it 22 years later in a revival theatre. My opinion had changed--it's even WORSE! Basically everything I hated about it was still there and the film was VERY 60s...and has dated badly. I got all the little in-jokes...too bad they weren't funny. The constant shifts in tone got quickly annoying and there's absolutely nothing to get a firm grip on. Some people will love this. I found it frustrating...by the end of the film I felt like throwing something heavy at the screen.<br /><br />Also, all the Monkees songs in this movie SUCK (and I DO like them).<br /><br />For ex-hippies only...or if you're stoned. I give this a 1.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e60f6789-4253-40ef-a77a-7ae6c5b8d244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at a saturday matinee in my home town i went with an older friend he was about 12 and my mom let me go because she thought the film would be ok it s rated g i was assaulted by loud music strange images no plot and a stubborn refusal to make any sense we left halfway through because we were bored frustrated and our ears hurt i saw it 22 years later in a revival theatre my opinion had changed it s even worse basically everything i hated about it was still there and the film was very 60s and has dated badly i got all the little in jokes too bad they weren t funny the constant shifts in tone got quickly annoying and there s absolutely nothing to get a firm grip on some people will love this i found it frustrating by the end of the film i felt like throwing something heavy at the screen also all the monkees songs in this movie suck and i do like them for ex hippies only or if you re stoned i give this a 1 '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(df.loc[0, 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af67e00c-0f4f-4aa5-80cd-d958b7b4e505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        at a saturday matinee in my home town i went w...\n",
       "1        i love this movie it is the first film master ...\n",
       "2        in the voice over which begins the film hughie...\n",
       "3         spoiler alert the point is though that i didn...\n",
       "4        this is an excellent film no it s not mel gibs...\n",
       "                               ...                        \n",
       "49995    although the director tried the filming was ma...\n",
       "49996    it has been about 50 years since a movie has b...\n",
       "49997     bar hopping seems to be trying to be about th...\n",
       "49998    this awful effort just goes to show what happe...\n",
       "49999    yes why among the filmmakers that came out in ...\n",
       "Name: sentiment, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe05c8-d821-488f-b652-1de413092873",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15607aba-6f50-4c39-b1c7-b2a956cd7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return( text.split() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc940244-f0b9-4a61-aa7a-4738f8e95c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['split', 'me', '!']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"split me !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "317d93db-037b-4c27-8900-9876b67a1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bd54681-7720-4d2a-b735-bf7a86c886a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ded103a0-224a-4a4c-98d2-b6772f0cdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_porter( text ):\n",
    "    return [ porter.stem(word) for word in text.split() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1facd3df-4bf6-4217-977e-8a8e11806f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'how', 'stemmer', 'work', 'they', 'are', 'pretti', 'good']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_porter(\"Testing how stemmers work they are pretty good \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac024d-eaab-425a-8f02-a7b313bbc594",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stop-Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9d73a03-8385-4f1c-8d86-dcb53cfa46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c12e377-8515-4d16-816b-ac386c07e459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ahmed4/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaa0d0d5-23e4-4372-b0ad-4121a4b274f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbf65dd6-50ca-4260-966b-e255999df8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff9d9949-3a36-4a50-b086-9a9389411dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"He was pretty good in describing his feelings about this scene. However, I think it was really awkward ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b39113f9-a7ba-4928-8e47-2c9ccf0e1fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wa',\n",
       " 'pretti',\n",
       " 'good',\n",
       " 'describ',\n",
       " 'hi',\n",
       " 'feel',\n",
       " 'thi',\n",
       " 'scene.',\n",
       " 'however,',\n",
       " 'think',\n",
       " 'wa',\n",
       " 'realli',\n",
       " 'awkward',\n",
       " '...']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in tokenizer_porter( text ) if w not in stop ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4e55e-2d00-4e20-9987-3a98c50fb19f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Training a logistic clf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "947100b0-9892-4dea-9be9-f475c4d24756",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[25000:, 'sentiment'].values\n",
    "X_test = df.loc[:25000, 'sentiment'].values\n",
    "y_train = df.loc[25000:, 'label'].values\n",
    "y_test = df.loc[:25000, 'label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60a198d0-8f84-4765-a453-5c9acd3f0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa8e23c8-8e71-4a34-b5b5-ee5e8d44b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdb03113-f8fb-4c41-bb61-795e35cb5b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.float64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': False,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'smooth_idf': True,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'sublinear_tf': False,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'use_idf': True,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4edaad25-ebe5-448a-8658-74e476478a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_grid_param = [\n",
    "    {\n",
    "        'vect__ngram_range':[(1,1)],\n",
    "        'vect__stop_words' :[None],\n",
    "        'vect__tokenizer'  :[tokenizer, tokenizer_porter],\n",
    "        'clf__penalty'     :['l2'],\n",
    "        'clf__C'           :[1.0,10.0]\n",
    "    },\n",
    "    {\n",
    "        'vect__ngram_range':[(1,1)],\n",
    "        'vect__stop_words' :[stop, None],\n",
    "        'vect__tokenizer'  :[tokenizer],\n",
    "        'vect__norm'       :[None],\n",
    "        'vect__use_idf'    :[False],\n",
    "        'clf__penalty'     :['l2'],\n",
    "        'clf__C'           :[1.0,10.0]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afa13aec-81ff-46ad-8782-bec614678e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf = Pipeline( [ ('vect', tfidf), (\"clf\", LogisticRegression( solver=\"liblinear\" ) ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8af9bf54-f033-48e0-9520-ff9dc5579d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, small_grid_param, scoring='accuracy', cv=5, verbose=2, n_jobs=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37dbfa-4bd7-461b-b0bc-8599c81359eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr_tfidf.fit(X_train, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7188d1-815d-43e5-8894-2995046bf174",
   "metadata": {},
   "source": [
    "## Out Of Core Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
