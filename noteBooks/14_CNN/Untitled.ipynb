{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d595231-099c-4165-b373-38db9ed65d95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Simple Convultion Implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639e27aa-98d8-44a2-9482-9023cb3ea1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9d7ff7d-c3aa-48ad-af4c-aa06972a872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv( x, w, s, p ):\n",
    "    x_pad = np.array(x)\n",
    "    w_rot = np.array(w[::-1])\n",
    "    if (p > 0):\n",
    "        pad = np.zeros( shape = p )\n",
    "        x_pad = np.concatenate( [pad, x, pad] )\n",
    "    res = []\n",
    "    for i in range( 0, int( len(x_pad) - len(w) ) + 1, s ):\n",
    "        res.append( np.sum(x_pad[i:i+w_rot.shape[0]] * w_rot))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "adc96f34-2e16-4725-9ea0-484558b82f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,12]\n",
    "w = [2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "96ae6f6f-ea3b-4b7f-8246-f1bfe8427df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros( shape = (2,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "445ab113-1659-4cef-bce6-54914fe60334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d( x, w, s = (1,1), p = (0,0) ):\n",
    "    w_rot = w[::-1,::-1]\n",
    "    x_orig = np.array(x)\n",
    "    \n",
    "    n1 = x_orig.shape[0] + 2*p[0]\n",
    "    n2 = x_orig.shape[1] + 2*p[1]\n",
    "    \n",
    "    x_padded = np.zeros(shape=(n1,n2))\n",
    "    x_padded[ p[0]:p[0] + x_orig.shape[0] , p[1]:p[1] + x_orig.shape[1] ] = x_orig\n",
    "\n",
    "    res = []\n",
    "    for i in range( 0, int( ( x_pad.shape[0] - w_rot.shape[0] ) / s[0] ) + 1, s[0] ):\n",
    "        res.append([])\n",
    "        for j in range( 0, int( ( x_pad.shape[1] - w_rot.shape[1] ) / s[1] ) + 1, s[1] ):\n",
    "            x_sub = x_padded[i:i+w_rot.shape[0], j:j+w_rot.shape[1]]\n",
    "            ret[-1].append(np.sum(x_sub * w_rot))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0366b-5031-4ddf-b172-2fc19e549edd",
   "metadata": {},
   "source": [
    "### Conv W. PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38776faf-dcc8-44fe-ae75-3f58981739e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    While small NNs are insufficient to capture the complexity of a real-word dataset, big NNs can be prone\n",
    "    to overfitting. To address this issue, we use regularization. There are 2 types: L1 & L2, while the latter\n",
    "    being more famous than the former. Furthermore, we have another method to restrict the weights which is\n",
    "    called `Dropout`. We will look in more detail for it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26706204-0126-4a9f-8ae2-778aa4bfff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a15aac81-3754-41a9-9772-df55686c5fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1070, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.BCELoss()\n",
    "loss = loss_func( torch.tensor([0.9]), torch.tensor([1.0]) )\n",
    "l2_lambda = 0.001\n",
    "conv_layer = nn.Conv2d( in_channels=3, out_channels=5, kernel_size=5 ) \n",
    "l2_penalty = l2_lambda * sum( [ ( p**2 ).sum() for p in conv_layer.parameters() ] )\n",
    "loss_with_penalty = l2_penalty + loss\n",
    "loss_with_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6174c15-369d-45f2-9ccf-1fc770cad1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1064)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear( in_features= 10, out_features= 16 )\n",
    "l2_penalty = l2_lambda * sum([( p**2 ).sum() for p in linear.parameters()])\n",
    "loss_with_penalty = loss + l2_lambda\n",
    "loss_with_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f098a-9f7c-46ec-a913-c600d8eeff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    When it comes to dropout, we tend to turn off some of the units so the recieving node does not\n",
    "    rely completely on one of them. Theis technique is quietly used in Computer Vision since\n",
    "    the data, almost always, is insufficient and the model is likely to overfit. In other applications\n",
    "    we dont bother using this technique until we see a potential of overfitting, because we\n",
    "    loose the ability to debug the NN or the code.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9689f01c-6f19-4f93-970c-80c3a8c83a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCELoss: tensor(0.3711)\n",
      "logits_BCELoss: tensor(0.3711)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([0.8])\n",
    "proba  = torch.sigmoid(logits)\n",
    "truth  = torch.tensor([1.0])\n",
    "bce_loss = nn.BCELoss()\n",
    "logits_bce = nn.BCEWithLogitsLoss()\n",
    "print(\"BCELoss:\", bce_loss(proba, truth ))\n",
    "print(\"logits_BCELoss:\", logits_bce(logits, truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2c51dbf-6967-48dc-85da-cfda5aaa2766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE_loss: tensor(0.3532)\n",
      "NLL_loss: tensor(0.3532)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[0.8, 2.1, 3.2]])\n",
    "proba  = torch.softmax(logits, dim = 1)\n",
    "truth  = torch.tensor([2])\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "nll_loss = nn.NLLLoss()\n",
    "print(\"CE_loss:\", ce_loss(logits, truth ))\n",
    "print(\"NLL_loss:\", nll_loss(torch.log(proba), truth ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8845959-8072-4cd6-bae8-53b5d0d85719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
